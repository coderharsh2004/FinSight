{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm5LIdNUhLV8",
        "outputId": "d198d610-3757-41d9-f4a4-651d47016fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping newspaper3k as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: lxml 5.3.1\n",
            "Uninstalling lxml-5.3.1:\n",
            "  Successfully uninstalled lxml-5.3.1\n",
            "Collecting lxml\n",
            "  Using cached lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Using cached lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "Installing collected packages: lxml\n",
            "Successfully installed lxml-5.3.1\n",
            "Collecting newspaper3k\n",
            "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (4.13.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Using cached cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.3.1)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.32.3)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Using cached tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Using cached feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Using cached jieba3k-0.35.1.zip (7.4 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Using cached tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2025.1.31)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Using cached requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.17.0)\n",
            "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "Using cached tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13539 sha256=8dabb1bb36be630e4bd8c4e78528242e7220a235eb9515706197a1a7aee55b5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/f8/cce3a9ae6d828bd346be695f7ff54612cd22b7cbd7208d68f3\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3342 sha256=b0bf82b28226d9909ccca763c3f527ffa3040f00a26b073c08296a08a80a3bb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/d5/72/9cd9eccc819636436c6a6e59c22a0fb1ec167beef141f56491\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398379 sha256=f3f8b2b9506f18ede851b7731b0615503bf80b72eedb167a3f5485e8273280b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/a1/46/8e68055c1713f9c4598774c15ad0541f26d5425ee7423b6493\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=34fee2ebc60994e82dec956c62496865f6550dd6dcae6073f313ec2f70902120\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y newspaper3k lxml\n",
        "!pip install --upgrade lxml lxml_html_clean\n",
        "!pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rHUy2bnhlI-",
        "outputId": "86313673-9ba9-4a4b-e1ec-d9a162c7f547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.11/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (4.13.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.3.1)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.32.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.1.3)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2025.1.31)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uvPGvSFhqr5",
        "outputId": "f14f1f4f-9804-4321-fe13-6df1059b3dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GoogleNews\n",
            "  Downloading GoogleNews-1.6.15-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from GoogleNews) (4.13.3)\n",
            "Collecting dateparser (from GoogleNews)\n",
            "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from GoogleNews) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->GoogleNews) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->GoogleNews) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->GoogleNews) (2025.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser->GoogleNews) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->GoogleNews) (5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->GoogleNews) (1.17.0)\n",
            "Downloading GoogleNews-1.6.15-py3-none-any.whl (8.8 kB)\n",
            "Downloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dateparser, GoogleNews\n",
            "Successfully installed GoogleNews-1.6.15 dateparser-1.2.1\n",
            "Collecting yahoo_fin\n",
            "  Downloading yahoo_fin-0.8.9.1-py3-none-any.whl.metadata (699 bytes)\n",
            "Collecting requests-html (from yahoo_fin)\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.11/dist-packages (from yahoo_fin) (6.0.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from yahoo_fin) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from yahoo_fin) (2.2.2)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser->yahoo_fin) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->yahoo_fin) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->yahoo_fin) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->yahoo_fin) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->yahoo_fin) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->yahoo_fin) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->yahoo_fin) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->yahoo_fin) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->yahoo_fin) (2025.1.31)\n",
            "Collecting pyquery (from requests-html->yahoo_fin)\n",
            "  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fake-useragent (from requests-html->yahoo_fin)\n",
            "  Downloading fake_useragent-2.0.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting parse (from requests-html->yahoo_fin)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting bs4 (from requests-html->yahoo_fin)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Collecting w3lib (from requests-html->yahoo_fin)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html->yahoo_fin)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html->yahoo_fin)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.6.1)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html->yahoo_fin)\n",
            "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.67.1)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->yahoo_fin)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html->yahoo_fin)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->yahoo_fin) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4->requests-html->yahoo_fin) (4.13.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html->yahoo_fin) (5.3.1)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html->yahoo_fin) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.6)\n",
            "Downloading yahoo_fin-0.8.9.1-py3-none-any.whl (10 kB)\n",
            "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading fake_useragent-2.0.3-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pyquery-2.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
            "Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: parse, appdirs, websockets, w3lib, urllib3, pyquery, pyee, fake-useragent, pyppeteer, bs4, requests-html, yahoo_fin\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.2\n",
            "    Uninstalling websockets-14.2:\n",
            "      Successfully uninstalled websockets-14.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 0.8.0 requires websockets<15.0dev,>=13.0, but you have websockets 10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 bs4-0.0.2 fake-useragent-2.0.3 parse-1.20.2 pyee-11.1.1 pyppeteer-2.0.0 pyquery-2.0.1 requests-html-0.10.0 urllib3-1.26.20 w3lib-2.3.1 websockets-10.4 yahoo_fin-0.8.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install GoogleNews\n",
        "!pip install yahoo_fin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --index-url=https://blpapi.bloomberg.com/repository/releases/python/simple/ blpapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbsZzgwqj_L_",
        "outputId": "19e1d305-bfac-4b30-b711-c3c607428dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://blpapi.bloomberg.com/repository/releases/python/simple/\n",
            "Collecting blpapi\n",
            "  Downloading https://blpapi.bloomberg.com/repository/releases/python/blpapi-3.25.1-py3-none-manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blpapi\n",
            "Successfully installed blpapi-3.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import nltk\n",
        "import spacy\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from newspaper import Article\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from GoogleNews import GoogleNews\n",
        "from yahoo_fin import news\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize NLP tools\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Keywords for Jio stock-related sentences\n",
        "keywords = [\"\"]# Enter Stock Specific keywords\n",
        "\n",
        "def is_relevant(text):\n",
        "    return any(keyword in text for keyword in keywords)\n",
        "\n",
        "# Used to Classify text on the basis of sentiment and Labelling it\n",
        "def classify_sentiment(text):\n",
        "    score = sia.polarity_scores(text)['compound']\n",
        "    if score > 0.1:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.1:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "# Scraping from NewsAPI\n",
        "def get_newsapi_links(api_key, num_articles=1000):\n",
        "    url = f\"https://newsapi.org/v2/everything?q=Jio+stock&sortBy=publishedAt&language=en&apiKey={api_key}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        return [article[\"url\"] for article in data.get(\"articles\", [])[:num_articles]]\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching NewsAPI links: {e}\")\n",
        "        return []\n",
        "\n",
        "#Scraping From NewsDataIO\n",
        "def get_newsdataio_links(api_key, num_articles=1000):\n",
        "    url = f\"https://newsdata.io/api/1/news?apikey={api_key}&q=Jio&language=en\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        return [article[\"link\"] for article in data.get(\"results\", [])[:num_articles]]\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching NewsData.io links: {e}\")\n",
        "        return []\n",
        "\n",
        "# Scraping From Google News\n",
        "def get_google_news_links(num_articles=1000):\n",
        "    googlenews = GoogleNews(lang=\"en\", period=\"7d\")\n",
        "    googlenews.search(\"Jio stock\")\n",
        "    results = googlenews.result()\n",
        "    return [article[\"link\"] for article in results[:num_articles]]\n",
        "\n",
        "\n",
        "# Scraping From Yahoo Finance\n",
        "def get_yahoo_finance_links(num_articles=1000):\n",
        "    articles = news.get_yf_rss(\"RELIANCE.NS\")  # Reliance Industries ticker symbol\n",
        "    return [article[\"link\"] for article in articles[:num_articles]]\n",
        "\n",
        "# Scraping From Alpha Vantage Links\n",
        "def get_alpha_vantage_links(api_key, num_articles=1000):\n",
        "    url = f\"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=RELIANCE.NS&apikey={api_key}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        return [article[\"url\"] for article in data.get(\"feed\", [])[:num_articles]]\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching Alpha Vantage news: {e}\")\n",
        "        return []\n",
        "\n",
        "#Scrpaing From Stock News\n",
        "def get_stocknewsapi_links(num_articles=5000, batch_size=100):\n",
        "    collected_urls = set()\n",
        "    page = 1\n",
        "\n",
        "    while len(collected_urls) < num_articles:\n",
        "        url = f\"https://stocknewsapi.com/api/v1?tickers=AXP&items={batch_size}&page={page}&token={STOCK_NEWS_API_KEY}\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            data = response.json()\n",
        "            new_links = {article[\"news_url\"] for article in data.get(\"data\", [])}\n",
        "            collected_urls.update(new_links)\n",
        "\n",
        "            print(f\"📡 Page {page}: Collected {len(new_links)} new articles. Total: {len(collected_urls)}\")\n",
        "            page += 1\n",
        "\n",
        "            if len(new_links) == 0:\n",
        "                break\n",
        "\n",
        "            time.sleep(1)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error fetching StockNewsAPI: {e}\")\n",
        "            break\n",
        "\n",
        "    return list(collected_urls)\n",
        "\n",
        "# Scraping text Over Here\n",
        "def scrape_text(url):\n",
        "    try:\n",
        "        article = Article(url)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        return article.text if is_relevant(article.title) else None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# API Keys (Replace with actual credentials)\n",
        "ALPHA_VANTAGE_KEY = \"8HOXVJD6FABJBNUQ\"\n",
        "NEWSAPI_KEY = \"a2bcdb25ffb4404ea911aa363e05b48c\"\n",
        "STOCK_NEWS_API_KEY = \"xvhgrwydlxpcg5pr1isujdpysapupc0s1sva8w9f\"\n",
        "NEWSDATAIO_KEY= \"pub_68826b6cd23d3d89ba30ec65d6472fd96b09c\"\n",
        "\n",
        "# Collecting stock news URLs\n",
        "urls = set(\n",
        "    get_newsapi_links(NEWSAPI_KEY, 1000) +\n",
        "    get_newsdataio_links(NEWSDATAIO_KEY, 1000) +\n",
        "    get_google_news_links(1000) +\n",
        "    get_yahoo_finance_links(1000) +\n",
        "    get_alpha_vantage_links(ALPHA_VANTAGE_KEY, 1000) +\n",
        "    get_stocknewsapi_links(5000)\n",
        ")\n",
        "print(f\"\\U0001F4E1 Total Jio News URLs Collected: {len(urls)}\")\n",
        "\n",
        "# Collecting sentences by class\n",
        "positive_sentences, negative_sentences, neutral_sentences = [], [], []\n",
        "\n",
        "for url in urls:\n",
        "    text = scrape_text(url)\n",
        "    if text:\n",
        "        extracted_sentences = sent_tokenize(text)\n",
        "        for sentence in extracted_sentences:\n",
        "            if is_relevant(sentence):\n",
        "                sentiment = classify_sentiment(sentence)\n",
        "                if sentiment == \"Positive\" and len(positive_sentences) < 10000:\n",
        "                    positive_sentences.append(sentence)\n",
        "                elif sentiment == \"Negative\" and len(negative_sentences) < 10000:\n",
        "                    negative_sentences.append(sentence)\n",
        "                elif sentiment == \"Neutral\" and len(neutral_sentences) < 10000:\n",
        "                    neutral_sentences.append(sentence)\n",
        "    if len(positive_sentences) >= 10000 and len(negative_sentences) >= 10000 and len(neutral_sentences) >= 10000:\n",
        "        break\n",
        "\n",
        "# Save data to CSV\n",
        "with open(\"stock_sentiment_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Sentence\", \"Sentiment\"])\n",
        "    writer.writerows([[s, \"Positive\"] for s in positive_sentences])\n",
        "    writer.writerows([[s, \"Negative\"] for s in negative_sentences])\n",
        "    writer.writerows([[s, \"Neutral\"] for s in neutral_sentences])\n",
        "\n",
        "print(f\"\\u2705 Scraped & labeled Jio stock news: {len(positive_sentences)} Positive, {len(negative_sentences)} Negative, {len(neutral_sentences)} Neutral!\")\n"
      ],
      "metadata": {
        "id": "WPO1Rn3co3us",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6143c5c0-e08a-4742-ad89-c2e093161bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📡 Page 1: Collected 0 new articles. Total: 0\n",
            "📡 Total Jio News URLs Collected: 69\n",
            "Error fetching https://economictimes.indiatimes.com/markets/stocks/stock-liveblog/jio-financial-services-share-price-live-updates-25-feb-2025/liveblog/118543911.cms&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIBxAC&usg=AOvVaw2g4Vo8O5NPvlvxiuAePbR9: Article `download()` failed with 404 Client Error: Not Found for url: https://economictimes.indiatimes.com/markets/stocks/stock-liveblog/jio-financial-services-share-price-live-updates-25-feb-2025/liveblog/118543911.cms&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIBxAC&usg=AOvVaw2g4Vo8O5NPvlvxiuAePbR9 on URL https://economictimes.indiatimes.com/markets/stocks/stock-liveblog/jio-financial-services-share-price-live-updates-25-feb-2025/liveblog/118543911.cms&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIBxAC&usg=AOvVaw2g4Vo8O5NPvlvxiuAePbR9\n",
            "Error fetching https://www.livemint.com/market/live-blog/jio-financial-services-share-price-today-latest-live-updates-on-25-feb-2025-11740450665739.html&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIAhAC&usg=AOvVaw2i8dQ17RMUMymFaI73eE95: Article `download()` failed with 404 Client Error: Not Found for url: https://www.livemint.com/market/live-blog/jio-financial-services-share-price-today-latest-live-updates-on-25-feb-2025-11740450665739.html&ved=2ahukewij7nvo1t-laxvcd0qihussdv0qxfqbegqiahac&usg=aovvaw2i8dq17rmumymfai73ee95 on URL https://www.livemint.com/market/live-blog/jio-financial-services-share-price-today-latest-live-updates-on-25-feb-2025-11740450665739.html&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIAhAC&usg=AOvVaw2i8dQ17RMUMymFaI73eE95\n",
            "Error fetching https://www.investing.com/news/stock-market-news/indias-religare-says-us-businessman-makes-competing-offer-for-stake-3830751: Article `download()` failed with 403 Client Error: Forbidden for url: https://www.investing.com/news/stock-market-news/indias-religare-says-us-businessman-makes-competing-offer-for-stake-3830751 on URL https://www.investing.com/news/stock-market-news/indias-religare-says-us-businessman-makes-competing-offer-for-stake-3830751\n",
            "Error fetching https://mivalle.net.ar/uncategorized-en/revolutionizing-finances-how-jio-finance-is-changing-the-game/103685/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQICRAC&usg=AOvVaw3aykC3eUxd6ZD8Zl-rRBHz: Article `download()` failed with 404 Client Error: Not Found for url: https://mivalle.net.ar/uncategorized-en/revolutionizing-finances-how-jio-finance-is-changing-the-game/103685/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQICRAC&usg=AOvVaw3aykC3eUxd6ZD8Zl-rRBHz on URL https://mivalle.net.ar/uncategorized-en/revolutionizing-finances-how-jio-finance-is-changing-the-game/103685/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQICRAC&usg=AOvVaw3aykC3eUxd6ZD8Zl-rRBHz\n",
            "Error fetching https://www.businesstoday.in/markets/company-stock/story/zomato-jio-financial-britannia-how-to-trade-these-three-stocks-amid-nifty-rejig-buzz-465811-2025-02-25&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQICBAC&usg=AOvVaw0kOas-SYe0k8jMm97LRcvO: Article `download()` failed with 404 Client Error: Not Found for url: https://www.businesstoday.in/markets/company-stock/story/zomato-jio-financial-britannia-how-to-trade-these-three-stocks-amid-nifty-rejig-buzz-465811-2025-02-25&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQICBAC&usg=AOvVaw0kOas-SYe0k8jMm97LRcvO on URL https://www.businesstoday.in/markets/company-stock/story/zomato-jio-financial-britannia-how-to-trade-these-three-stocks-amid-nifty-rejig-buzz-465811-2025-02-25&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQICBAC&usg=AOvVaw0kOas-SYe0k8jMm97LRcvO\n",
            "Error fetching https://www.hindustantimes.com/opinion/the-taste-by-vir-sanghvi-how-the-white-lotus-is-reshaping-luxury-tourism-and-hotel-marketing-strategies-101740472008123.html: Article `download()` failed with 403 Client Error: Forbidden for url: https://www.hindustantimes.com/opinion/the-taste-by-vir-sanghvi-how-the-white-lotus-is-reshaping-luxury-tourism-and-hotel-marketing-strategies-101740472008123.html on URL https://www.hindustantimes.com/opinion/the-taste-by-vir-sanghvi-how-the-white-lotus-is-reshaping-luxury-tourism-and-hotel-marketing-strategies-101740472008123.html\n",
            "Error fetching https://www.tgnns.com/news/insights-into-jio-financial-services-and-citigroup-stock/2025/02/24/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIAxAC&usg=AOvVaw2EBq6xMEWsGgEObBBKqmUA: Article `download()` failed with 404 Client Error: Not Found for url: https://www.tgnns.com/news/insights-into-jio-financial-services-and-citigroup-stock/2025/02/24/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIAxAC&usg=AOvVaw2EBq6xMEWsGgEObBBKqmUA on URL https://www.tgnns.com/news/insights-into-jio-financial-services-and-citigroup-stock/2025/02/24/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIAxAC&usg=AOvVaw2EBq6xMEWsGgEObBBKqmUA\n",
            "Error fetching https://www.forbes.com/sites/greatspeculations/2025/02/12/whats-happening-with-cflt-stock/: Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/greatspeculations/2025/02/12/whats-happening-with-cflt-stock/ on URL https://www.forbes.com/sites/greatspeculations/2025/02/12/whats-happening-with-cflt-stock/\n",
            "Error fetching https://www.ndtv.com/opinion/move-over-middle-class-replicants-are-coming-7675572: Article `download()` failed with 403 Client Error: Forbidden for url: https://www.ndtv.com/opinion/move-over-middle-class-replicants-are-coming-7675572 on URL https://www.ndtv.com/opinion/move-over-middle-class-replicants-are-coming-7675572\n",
            "Error fetching https://tradebrains.in/zomato-will-it-lead-to-more-volatility/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIARAC&usg=AOvVaw3ZXsYKCcO85k-RfCItxHI3: Article `download()` failed with 404 Client Error: Not Found for url: https://tradebrains.in/zomato-will-it-lead-to-more-volatility/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIARAC&usg=AOvVaw3ZXsYKCcO85k-RfCItxHI3 on URL https://tradebrains.in/zomato-will-it-lead-to-more-volatility/&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIARAC&usg=AOvVaw3ZXsYKCcO85k-RfCItxHI3\n",
            "Error fetching https://www.forbes.com/sites/yessarrosendar/2025/02/18/billionaire-sunil-mittal-sells-bharti-airtel-shares-worth-976-million/: Article `download()` failed with 403 Client Error: Max restarts limit reached for url: https://www.forbes.com/sites/yessarrosendar/2025/02/18/billionaire-sunil-mittal-sells-bharti-airtel-shares-worth-976-million/ on URL https://www.forbes.com/sites/yessarrosendar/2025/02/18/billionaire-sunil-mittal-sells-bharti-airtel-shares-worth-976-million/\n",
            "Error fetching https://www.businesstoday.in/markets/stocks/story/jio-financial-shares-up-4-from-52-week-low-level-which-way-is-the-stock-headed-465877-2025-02-25&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIABAC&usg=AOvVaw1Y6xX-QuVSHct0JbKCaQmD: Article `download()` failed with 404 Client Error: Not Found for url: https://www.businesstoday.in/markets/stocks/story/jio-financial-shares-up-4-from-52-week-low-level-which-way-is-the-stock-headed-465877-2025-02-25&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIABAC&usg=AOvVaw1Y6xX-QuVSHct0JbKCaQmD on URL https://www.businesstoday.in/markets/stocks/story/jio-financial-shares-up-4-from-52-week-low-level-which-way-is-the-stock-headed-465877-2025-02-25&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIABAC&usg=AOvVaw1Y6xX-QuVSHct0JbKCaQmD\n",
            "Error fetching https://www.livemint.com/market/live-blog/jio-financial-services-share-price-today-latest-live-updates-on-24-feb-2025-11740364286424.html&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIBRAC&usg=AOvVaw2HdWNFmeBE_JZvHn3XveMQ: Article `download()` failed with 404 Client Error: Not Found for url: https://www.livemint.com/market/live-blog/jio-financial-services-share-price-today-latest-live-updates-on-24-feb-2025-11740364286424.html&ved=2ahukewij7nvo1t-laxvcd0qihussdv0qxfqbegqibrac&usg=aovvaw2hdwnfmebe_jzvhn3xvemq on URL https://www.livemint.com/market/live-blog/jio-financial-services-share-price-today-latest-live-updates-on-24-feb-2025-11740364286424.html&ved=2ahUKEwiJ7Nvo1t-LAxVCD0QIHUssDV0QxfQBegQIBRAC&usg=AOvVaw2HdWNFmeBE_JZvHn3XveMQ\n",
            "✅ Scraped & labeled Jio stock news: 36 Positive, 2 Negative, 7 Neutral!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-zk4Lj0z1DQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}